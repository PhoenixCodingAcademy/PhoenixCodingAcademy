# Large Language Models (LLMs) Glossary

## Model
A mathematical system trained on large amounts of text data that can understand and generate human-like text. The model learns patterns and relationships in language during training, allowing it to perform tasks like text completion, translation, summarization, and question answering. Popular models include GPT-4, Claude, Gemini, and open source models like Llama.

Key characteristics:
- Trained on massive text datasets (hundreds of billions of tokens)
- Uses neural network architectures (typically transformer-based)
- Can understand context and generate coherent responses
- Improves with larger model sizes and more training data
- Requires significant computing resources to train
